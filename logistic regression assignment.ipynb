{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7sT-3oM5Q_y"
   },
   "source": [
    "# Supervised Learning: Regression Models and Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1xI72w_5bQ1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-5E-o3x5k_p"
   },
   "source": [
    "## Question 1: What is Simple Linear Regression (SLR)? Explain its purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ7vG-6F5qO4"
   },
   "source": [
    "**Simple Linear Regression (SLR)** is a statistical method used to model and analyze the relationship between two continuous variables.\n",
    "\n",
    "It involves:\n",
    "* An **independent variable** (predictor or explanatory variable), denoted as X.\n",
    "* A **dependent variable** (response or outcome variable), denoted as Y.\n",
    "\n",
    "### Purpose of SLR\n",
    "\n",
    "The primary purpose of Simple Linear Regression is to understand and quantify the relationship between the independent and dependent variables. Specifically, it aims to:\n",
    "1.  **Model the Relationship**: Find the best-fitting straight line (called the regression line) that describes how the dependent variable `Y` changes as the independent variable `X` changes.\n",
    "2.  **Make Predictions**: Use the established linear relationship to predict the value of the dependent variable (`Y`) for a given value of the independent variable (`X`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iRjY32P53q8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i4T1zS054iT"
   },
   "source": [
    "## Question 2: What are the key assumptions of Simple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D26b_GgI5-fX"
   },
   "source": [
    "For a Simple Linear Regression model to be accurate and reliable, several key assumptions about the data must be met:\n",
    "\n",
    "1.  **Linearity**: The relationship between the independent variable (X) and the dependent variable (Y) is linear. This means that a straight line is the best way to represent their relationship.\n",
    "\n",
    "2.  **Independence**: The residuals (the differences between the actual and predicted values) are independent. This means the error of one observation is not influenced by the error of another. This is particularly important for time-series data.\n",
    "\n",
    "3.  **Homoscedasticity** (Constant Variance): The variance of the residuals is constant for all values of X. In simpler terms, the spread of the errors should be roughly the same across all points along the regression line.\n",
    "\n",
    "4.  **Normality of Residuals**: The residuals of the model are normally distributed. This assumption is important for conducting hypothesis tests and constructing confidence intervals.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8l5KxI86Jc-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C74Ie2-H6KRe"
   },
   "source": [
    "## Question 3: Write the mathematical equation for a simple linear regression model and explain each term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0x8L-P_6Mv-"
   },
   "source": [
    "The mathematical equation for a simple linear regression model is:\n",
    "\n",
    "$$ Y = \\beta_0 + \\beta_1X + \\epsilon $$\n",
    "\n",
    "Each term in the equation represents:\n",
    "\n",
    "* **Y**: The **dependent variable**. This is the outcome or the variable you are trying to predict.\n",
    "\n",
    "* **X**: The **independent variable**. This is the predictor or the variable you are using to make the prediction.\n",
    "\n",
    "* **$\\beta_0$ (Beta 0)**: The **y-intercept** of the regression line. It is the predicted value of `Y` when `X` is equal to 0.\n",
    "\n",
    "* **$\\beta_1$ (Beta 1)**: The **slope** of the regression line. It represents the change in the dependent variable `Y` for every one-unit increase in the independent variable `X`.\n",
    "\n",
    "* **$\\epsilon$ (Epsilon)**: The **error term**. This represents the random variability in the data that is not explained by the model. It accounts for the difference between the actual observed value of `Y` and the value predicted by the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j168W0r6P7K"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L9JvD836Qo_"
   },
   "source": [
    "## Question 4: Provide a real-world example where simple linear regression can be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0t8gW3d6Snx"
   },
   "source": [
    "A classic real-world example of simple linear regression is **predicting a student's final exam score based on the number of hours they studied**.\n",
    "\n",
    "* **Independent Variable (X)**: Number of hours studied.\n",
    "* **Dependent Variable (Y)**: Final exam score (e.g., out of 100).\n",
    "\n",
    "**Application:**\n",
    "\n",
    "A university could collect data on students' study hours and their corresponding exam scores. By fitting a simple linear regression model, they could establish a relationship, such as: `Score = 35 + 5 * (Hours Studied)`. \n",
    "\n",
    "This model could then be used to:\n",
    "- **Predict performance**: Estimate the expected score for a student who studies a certain number of hours.\n",
    "- **Offer guidance**: Advise students that, on average, each additional hour of study could improve their score by 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_zBf1wI6VDV"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI8_E6xS6VtI"
   },
   "source": [
    "## Question 5: What is the method of least squares in linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9wK8V1V6X73"
   },
   "source": [
    "The **method of least squares** is the standard technique used to determine the best-fitting line for a dataset in linear regression.\n",
    "\n",
    "Its main goal is to find the values for the intercept ($\\beta_0$) and the slope ($\\beta_1$) that **minimize the sum of the squared residuals**.\n",
    "\n",
    "### How It Works:\n",
    "1.  A **residual** is the vertical distance between an actual data point and the predicted point on the regression line. It represents the prediction error for that data point.\n",
    "2.  For each data point, this residual is calculated and then squared.\n",
    "3.  The method of least squares finds the unique line that makes the sum of all these squared residuals as small as possible—hence the name \"least squares.\"\n",
    "\n",
    "By minimizing this sum, it finds the line that is, on average, closest to all the data points.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR8pYhJq6Z8O"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN_gLdJ56aoc"
   },
   "source": [
    "## Question 6: What is Logistic Regression? How does it differ from Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L14U341p6cnI"
   },
   "source": [
    "**Logistic Regression** is a supervised learning algorithm used for **classification** problems, where the goal is to predict a categorical outcome. Unlike linear regression, which predicts a continuous value, logistic regression predicts the probability that an observation belongs to a particular category (e.g., the probability of an email being spam or not spam).\n",
    "\n",
    "### Key Differences from Linear Regression:\n",
    "\n",
    "| Feature | Linear Regression | Logistic Regression |\n",
    "|---|---|---|\n",
    "| **Primary Use Case** | Regression (predicting continuous values) | Classification (predicting discrete categories) |\n",
    "| **Output** | A continuous numerical value (e.g., 150.7, -23.5) | A probability between 0 and 1 |\n",
    "| **Relationship** | Models a linear relationship | Models the probability using a logistic (sigmoid) function |\n",
    "| **Equation** | $Y = \\beta_0 + \\beta_1X$ | $P(Y=1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X)}}$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8-f_c3u6iXz"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-6-zK_z6i-d"
   },
   "source": [
    "## Question 7: Name and briefly describe three common evaluation metrics for regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l3l4G756l0C"
   },
   "source": [
    "Here are three common metrics used to evaluate the performance of regression models:\n",
    "\n",
    "1.  **Mean Absolute Error (MAE)**\n",
    "    * **Description**: MAE calculates the average of the absolute differences between the actual and predicted values.\n",
    "    * **Interpretation**: It gives a straightforward idea of the average magnitude of the errors in the predictions, in the same units as the target variable.\n",
    "\n",
    "2.  **Mean Squared Error (MSE)**\n",
    "    * **Description**: MSE calculates the average of the squared differences between the actual and predicted values.\n",
    "    * **Interpretation**: By squaring the errors, it penalizes larger errors more heavily than smaller ones. This is useful when large errors are particularly undesirable.\n",
    "\n",
    "3.  **R-squared (R²)**\n",
    "    * **Description**: Also known as the coefficient of determination, R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "    * **Interpretation**: It provides a measure of how well the model explains the variability of the data, with values ranging from 0 to 1 (or 0% to 100%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9d0Vl9q6qH-"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJvM0iQ16q-m"
   },
   "source": [
    "## Question 8: What is the purpose of the R-squared metric in regression analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUa0dO8y6sWv"
   },
   "source": [
    "The primary purpose of the **R-squared (R²)** metric is to measure the **goodness of fit** of a regression model.\n",
    "\n",
    "Specifically, R-squared quantifies the proportion (or percentage) of the total variance in the dependent variable (Y) that can be explained by the variation in the independent variable(s) (X) included in the model.\n",
    "\n",
    "**In simple terms:**\n",
    "- An R-squared of **0.85** means that **85%** of the changes in the dependent variable can be explained by the changes in the independent variables.\n",
    "- An R-squared of **0** means that the model explains **none** of the variability.\n",
    "- An R-squared of **1** means that the model explains **all** of the variability.\n",
    "\n",
    "It helps analysts understand how well their model is capturing the underlying patterns in the data. A higher R-squared generally indicates a better fit, although it should be used in conjunction with other metrics for a complete evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE3qI5B26voH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBq-mYjS6wWv"
   },
   "source": [
    "## Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9UaL8lJ6yQx",
    "outputId": "1e11ed4e-9828-4448-93e1-7bd541e2f5ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equation for the regression line is: y = 42.18 + 6.57x\n",
      "--------------------------------------------------\n",
      "Intercept (β0): 42.18\n",
      "Slope (β1):     6.57\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample Data: Let's use the example of hours studied vs. exam scores\n",
    "# X = Hours Studied (Independent Variable)\n",
    "# y = Exam Score (Dependent Variable)\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8]).reshape(-1, 1)  # Needs to be a 2D array for scikit-learn\n",
    "y = np.array([50, 55, 68, 72, 75, 84, 90, 95])\n",
    "\n",
    "# 1. Create a Linear Regression model object\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2. Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# 3. Get the slope and intercept from the fitted model\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "# 4. Print the results\n",
    "print(f\"The equation for the regression line is: y = {intercept:.2f} + {slope:.2f}x\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"Intercept (β0): {intercept:.2f}\")\n",
    "print(f\"Slope (β1):     {slope:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W61Yn-m_6_zM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USbEEXqg7ABW"
   },
   "source": [
    "## Question 10: How do you interpret the coefficients in a simple linear regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_qJjM9o7Bx3"
   },
   "source": [
    "In a simple linear regression model, there are two coefficients to interpret: the intercept ($\\beta_0$) and the slope ($\\beta_1$).\n",
    "\n",
    "### 1. Interpreting the Intercept ($\\beta_0$)\n",
    "\n",
    "The **intercept** represents the **predicted value of the dependent variable (Y) when the independent variable (X) is 0**.\n",
    "\n",
    "* **Example**: In our `hours studied vs. exam score` model, if the intercept is 42.18, it means that a student who studies for **0 hours** is predicted to get a score of **42.18**. \n",
    "* **Caution**: The interpretation is only meaningful if X=0 is a realistic and relevant value within the context of the data. If X can never be zero (e.g., if X is a person's weight), the intercept serves mainly as a mathematical baseline for the line.\n",
    "\n",
    "### 2. Interpreting the Slope ($\\beta_1$)\n",
    "\n",
    "The **slope** represents the **estimated change in the dependent variable (Y) for a one-unit increase in the independent variable (X)**.\n",
    "\n",
    "* **Example**: If the slope for our model is 6.57, it means that for **each additional hour** a student studies, their exam score is predicted to **increase by 6.57 points**, on average.\n",
    "* The sign of the slope indicates the direction of the relationship:\n",
    "    * A **positive slope** means Y increases as X increases.\n",
    "    * A **negative slope** means Y decreases as X increases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}