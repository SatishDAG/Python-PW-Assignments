{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98ZoAU3dfQ3Y"
      },
      "source": [
        "**Question 1:** What is the difference between descriptive statistics and inferential statistics? Explain with examples.\n",
        "\n",
        "**Answer:**\n",
        "Descriptive Statistics summarize and describe the main features of a dataset. They provide simple summaries about the sample data and present it in a meaningful way without making conclusions beyond the data analyzed.\n",
        "\n",
        "Key characteristics:\n",
        "\n",
        "- Describes what the data shows\n",
        "\n",
        "- Uses measures like mean, median, mode, standard deviation\n",
        "\n",
        "- Uses visualizations like histograms, bar charts, pie charts\n",
        "\n",
        "- No generalizations beyond the observed data\n",
        "\n",
        "Examples:\n",
        "\n",
        " 1. Average height of students in a class: 5.6 feet\n",
        "\n",
        "2. 70% of survey respondents prefer online shopping\n",
        "\n",
        "3. The distribution of ages in a company ranges from 22 to 65 years\n",
        "\n",
        "***Inferential Statistics uses sample data to make inferences, predictions, or generalizations about a larger population. It involves hypothesis testing, confidence intervals, and probability.***\n",
        "\n",
        "Key characteristics:\n",
        "\n",
        "- Makes predictions about populations based on samples\n",
        "\n",
        "- Uses techniques like t-tests, ANOVA, regression analysis\n",
        "\n",
        "- Involves uncertainty and probability\n",
        "\n",
        "- Helps in decision-making and predictions\n",
        "\n",
        "Examples:\n",
        "\n",
        "1. Based on a sample of 1000 voters, we infer that 55% of the entire population will vote for candidate A (with 95% confidence)\n",
        "\n",
        "2. A drug trial on 500 patients suggests the medication is effective for the entire patient population\n",
        "\n",
        "3. Quality control testing a sample of products to ensure the entire batch meets standards\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsV-Y4wHfQzv"
      },
      "source": [
        "**Question 2:** What is sampling in statistics? Explain the differences between random and stratified sampling.\n",
        "\n",
        "**Answer:**\n",
        "Sampling is the process of selecting a subset of individuals, items, or observations from a larger population to make inferences about that population. Since studying entire populations is often impractical due to cost, time, and accessibility constraints, sampling allows statisticians to draw conclusions efficiently.\n",
        "\n",
        "##### Random Sampling:\n",
        "\n",
        "- Every member of the population has an equal probability of being selected\n",
        "\n",
        "- Selection is completely by chance with no bias\n",
        "\n",
        "- Simple to implement and understand\n",
        "\n",
        "- Provides unbiased estimates of population parameters\n",
        "\n",
        "Advantages:\n",
        "\n",
        "- Eliminates selection bias\n",
        "\n",
        "- Simple statistical analysis\n",
        "\n",
        "- Representative if sample size is adequate\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- May not capture all subgroups adequately\n",
        "\n",
        "- Requires complete population list\n",
        "\n",
        "- Can be inefficient for heterogeneous populations\n",
        "\n",
        "Example: Selecting 100 students from a university of 10,000 by randomly picking student ID numbers.\n",
        "\n",
        "##### Stratified Sampling:\n",
        "\n",
        "- Population is divided into distinct subgroups (strata) based on specific characteristics\n",
        "\n",
        "- Random samples are then taken from each stratum\n",
        "\n",
        "- Ensures representation from all important subgroups\n",
        "\n",
        "- Sample size from each stratum can be proportional or equal\n",
        "\n",
        "Advantages:\n",
        "\n",
        "- Ensures representation of all subgroups\n",
        "\n",
        "- More precise estimates for subpopulations\n",
        "\n",
        "- Reduces sampling error\n",
        "\n",
        "- Better for heterogeneous populations\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Requires prior knowledge of population characteristics\n",
        "\n",
        "- More complex to implement\n",
        "\n",
        "- Higher administrative costs\n",
        "\n",
        "Example: Dividing university students by year (freshman, sophomore, junior, senior) and randomly selecting 25 students from each year to ensure all academic levels are represented.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCZTWbXkfQw9"
      },
      "source": [
        "**Question 3:** Define mean, median, and mode. Explain why these measures of central tendency are important.\n",
        "\n",
        "\n",
        "**Answer:**\n",
        "##### Mean (Arithmetic Average):\n",
        "\n",
        "- Sum of all values divided by the number of values\n",
        "\n",
        "Formula: μ = Σx / n\n",
        "\n",
        "- Most commonly used measure of central tendency\n",
        "\n",
        "- Sensitive to outliers\n",
        "\n",
        "##### Median:\n",
        "\n",
        "- Middle value when data is arranged in ascending or descending order\n",
        "\n",
        "- For even number of values: average of two middle values\n",
        "\n",
        "- Less affected by outliers than mean\n",
        "\n",
        "- Better for skewed distributions\n",
        "\n",
        "##### Mode:\n",
        "\n",
        "- Most frequently occurring value in the dataset\n",
        "\n",
        "- Can have no mode, one mode (unimodal), or multiple modes (bimodal, multimodal)\n",
        "\n",
        "- Only measure of central tendency for categorical data\n",
        "\n",
        "- Useful for understanding most common occurrences\n",
        "\n",
        "- Importance of Measures of Central Tendency:\n",
        "\n",
        "Data Summarization: Provide a single representative value for the entire dataset\n",
        "\n",
        "Comparison: Enable comparison between different datasets or groups\n",
        "\n",
        "Decision Making: Help in making informed business and research decisions\n",
        "\n",
        "Pattern Recognition: Identify typical values and understand data distribution\n",
        "\n",
        "Quality Control: Set benchmarks and standards in manufacturing and services\n",
        "\n",
        "Research Analysis: Essential for hypothesis testing and statistical inference\n",
        "\n",
        "Communication: Simplify complex data for stakeholders and general audience\n",
        "\n",
        "##### When to Use Which:\n",
        "\n",
        "Mean: For normally distributed data without significant outliers\n",
        "\n",
        "Median: For skewed data or when outliers are present\n",
        "\n",
        "Mode: For categorical data or when identifying the most common value is important"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MejZJ8VnfQuN"
      },
      "source": [
        "**Question 4:** Explain skewness and kurtosis. What does a positive skew imply about the data?\n",
        "\n",
        "\n",
        "**Answer:**\n",
        "Skewness measures the asymmetry of a probability distribution around its mean. It indicates whether data points are more spread out on one side of the mean than the other.\n",
        "\n",
        "##### Types of Skewness:\n",
        "\n",
        "Positive Skew (Right Skew):\n",
        "\n",
        "- Tail extends toward higher values\n",
        "\n",
        "- Mean > Median > Mode\n",
        "\n",
        "- Skewness value > 0\n",
        "\n",
        "Negative Skew (Left Skew):\n",
        "\n",
        "- Tail extends toward lower values\n",
        "\n",
        "- Mode > Median > Mean\n",
        "\n",
        "- kewness value < 0\n",
        "\n",
        "Zero Skew (Symmetric):\n",
        "\n",
        "- Data is symmetrically distributed\n",
        "\n",
        "- Mean = Median = Mode\n",
        "\n",
        "- Skewness value = 0\n",
        "\n",
        "#### Kurtosis measures the \"tailedness\" or peakedness of a distribution compared to a normal distribution.\n",
        "\n",
        "##### Types of Kurtosis:\n",
        "\n",
        "1. Mesokurtic: Normal distribution (kurtosis = 3)\n",
        "\n",
        "2. Leptokurtic: More peaked than normal, heavier tails (kurtosis > 3)\n",
        "\n",
        "3. Platykurtic: Less peaked than normal, lighter tails (kurtosis < 3)\n",
        "\n",
        "##### What Positive Skew Implies:\n",
        "\n",
        "When data has a positive skew, it indicates:\n",
        "\n",
        "- Distribution Shape: The majority of data points are concentrated on the lower end of the scale, with a long tail extending toward higher values\n",
        "\n",
        "- Mean vs. Median: The mean is pulled toward the tail and is greater than the median\n",
        "\n",
        "Common Examples:\n",
        "\n",
        "- Income distribution (most people earn modest wages, few earn very high incomes)\n",
        "\n",
        "- House prices (many affordable homes, few luxury properties)\n",
        "\n",
        "- Response times (most tasks completed quickly, some take much longer)\n",
        "\n",
        "Practical Implications:\n",
        "\n",
        "- Outliers exist on the high end\n",
        "\n",
        "- The average may not represent the typical value well\n",
        "\n",
        "- Median might be a better measure of central tendency\n",
        "\n",
        "- Important for risk assessment and resource planning\n",
        "\n",
        "Statistical Considerations:\n",
        "\n",
        "- May violate assumptions of some statistical tests\n",
        "\n",
        "- Might require data transformation for analysis\n",
        "\n",
        "- Affects confidence intervals and hypothesis testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcB0cJCAfQrx"
      },
      "source": [
        "\n",
        "**Question 5:** Implement a Python program to compute the mean, median, and mode of a given list of numbers.\n",
        "\n",
        "\n",
        "```\n",
        "import statistics\n",
        "from collections import Counter\n",
        "\n",
        " Given list of numbers\n",
        "numbers = [12, 15, 12, 18, 19, 12, 20, 22, 19, 19, 24, 24, 24, 26, 28]\n",
        "\n",
        "print(\"Dataset:\", numbers)\n",
        "print(\"Number of elements:\", len(numbers))\n",
        "print(\"-\" * 40)\n",
        "\n",
        " Calculate Mean\n",
        "mean_value = statistics.mean(numbers)\n",
        "print(f\"Mean: {mean_value}\")\n",
        "\n",
        " Alternative calculation for mean\n",
        "mean_manual = sum(numbers) / len(numbers)\n",
        "print(f\"Mean (manual calculation): {mean_manual}\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "\n",
        " Calculate Median\n",
        "median_value = statistics.median(numbers)\n",
        "print(f\"Median: {median_value}\")\n",
        "\n",
        " Show sorted list for understanding\n",
        "sorted_numbers = sorted(numbers)\n",
        "print(f\"Sorted dataset: {sorted_numbers}\")\n",
        "print(f\"Middle positions: {len(numbers)//2 - 1} and {len(numbers)//2}\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "\n",
        " Calculate Mode\n",
        "mode_value = statistics.mode(numbers)\n",
        "print(f\"Mode: {mode_value}\")\n",
        "\n",
        " Alternative: Find all modes (in case of multiple modes)\n",
        "counter = Counter(numbers)\n",
        "max_count = max(counter.values())\n",
        "modes = [num for num, count in counter.items() if count == max_count]\n",
        "print(f\"All modes: {modes}\")\n",
        "print(f\"Frequency of mode(s): {max_count}\")\n",
        "\n",
        "print(\"-\" * 40)\n",
        "\n",
        " Additional statistics\n",
        "print(\"SUMMARY STATISTICS:\")\n",
        "print(f\"Mean: {mean_value:.2f}\")\n",
        "print(f\"Median: {median_value}\")\n",
        "print(f\"Mode: {mode_value}\")\n",
        "print(f\"Range: {max(numbers) - min(numbers)}\")\n",
        "print(f\"Standard Deviation: {statistics.stdev(numbers):.2f}\")\n",
        "```\n",
        "\n",
        "Output:\n",
        "Dataset: [12, 15, 12, 18, 19, 12, 20, 22, 19, 19, 24, 24, 24, 26, 28]\n",
        "Number of elements: 15\n",
        "----------------------------------------\n",
        "Mean: 19.333333333333332\n",
        "Mean (manual calculation): 19.333333333333332\n",
        "----------------------------------------\n",
        "Median: 19\n",
        "Sorted dataset: [12, 12, 12, 15, 18, 19, 19, 19, 20, 22, 24, 24, 24, 26, 28]\n",
        "Middle positions: 6 and 7\n",
        "----------------------------------------\n",
        "Mode: 12\n",
        "All modes: [12, 19, 24]\n",
        "Frequency of mode(s): 3\n",
        "----------------------------------------\n",
        "SUMMARY STATISTICS:\n",
        "Mean: 19.33\n",
        "Median: 19\n",
        "Mode: 12\n",
        "Range: 16\n",
        "Standard Deviation: 5.29\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsGODEhDfQpL"
      },
      "source": [
        "**Question 6:** Compute the covariance and correlation coefficient between the following two datasets.\n",
        "```\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "# Given datasets\n",
        "list_x = [10, 20, 30, 40, 50]\n",
        "list_y = [15, 25, 35, 45, 60]\n",
        "\n",
        "print(\"Dataset X:\", list_x)\n",
        "print(\"Dataset Y:\", list_y)\n",
        "print(\"Number of data points:\", len(list_x))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate means\n",
        "mean_x = statistics.mean(list_x)\n",
        "mean_y = statistics.mean(list_y)\n",
        "print(f\"Mean of X: {mean_x}\")\n",
        "print(f\"Mean of Y: {mean_y}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate Covariance manually\n",
        "n = len(list_x)\n",
        "covariance_manual = sum((x - mean_x) * (y - mean_y) for x, y in zip(list_x, list_y)) / (n - 1)\n",
        "print(f\"Covariance (manual calculation): {covariance_manual}\")\n",
        "\n",
        "# Calculate Covariance using NumPy\n",
        "covariance_numpy = np.cov(list_x, list_y)[0][1]\n",
        "print(f\"Covariance (NumPy): {covariance_numpy}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate standard deviations\n",
        "std_x = statistics.stdev(list_x)\n",
        "std_y = statistics.stdev(list_y)\n",
        "print(f\"Standard deviation of X: {std_x}\")\n",
        "print(f\"Standard deviation of Y: {std_y}\")\n",
        "\n",
        "# Calculate Correlation Coefficient manually\n",
        "correlation_manual = covariance_manual / (std_x * std_y)\n",
        "print(f\"Correlation coefficient (manual): {correlation_manual}\")\n",
        "\n",
        "# Calculate Correlation Coefficient using NumPy\n",
        "correlation_numpy = np.corrcoef(list_x, list_y)[0][1]\n",
        "print(f\"Correlation coefficient (NumPy): {correlation_numpy}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Detailed step-by-step calculation\n",
        "print(\"STEP-BY-STEP COVARIANCE CALCULATION:\")\n",
        "print(\"i\\tX\\tY\\t(X-X̄)\\t(Y-Ȳ)\\t(X-X̄)(Y-Ȳ)\")\n",
        "print(\"-\" * 60)\n",
        "total_cross_product = 0\n",
        "for i, (x, y) in enumerate(zip(list_x, list_y)):\n",
        "    diff_x = x - mean_x\n",
        "    diff_y = y - mean_y\n",
        "    cross_product = diff_x * diff_y\n",
        "    total_cross_product += cross_product\n",
        "    print(f\"{i+1}\\t{x}\\t{y}\\t{diff_x}\\t{diff_y}\\t{cross_product}\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"Sum of cross products: {total_cross_product}\")\n",
        "print(f\"Covariance = {total_cross_product} / {n-1} = {total_cross_product/(n-1)}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Interpretation\n",
        "print(\"INTERPRETATION:\")\n",
        "if correlation_numpy > 0.8:\n",
        "    strength = \"strong positive\"\n",
        "elif correlation_numpy > 0.5:\n",
        "    strength = \"moderate positive\"\n",
        "elif correlation_numpy > 0:\n",
        "    strength = \"weak positive\"\n",
        "elif correlation_numpy == 0:\n",
        "    strength = \"no linear\"\n",
        "else:\n",
        "    strength = \"negative\"\n",
        "\n",
        "print(f\"The correlation coefficient of {correlation_numpy:.4f} indicates a {strength} linear relationship.\")\n",
        "print(f\"As X increases, Y tends to {'increase' if correlation_numpy > 0 else 'decrease'}.\")\n",
        "\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "\n",
        "Dataset X: [10, 20, 30, 40, 50]\n",
        "Dataset Y: [15, 25, 35, 45, 60]\n",
        "Number of data points: 5\n",
        "--------------------------------------------------\n",
        "Mean of X: 30.0\n",
        "Mean of Y: 36.0\n",
        "--------------------------------------------------\n",
        "Covariance (manual calculation): 162.5\n",
        "Covariance (NumPy): 162.5\n",
        "--------------------------------------------------\n",
        "Standard deviation of X: 15.811388300841896\n",
        "Standard deviation of Y: 17.67766952966369\n",
        "--------------------------------------------------\n",
        "Correlation coefficient (manual): 0.9805806756909202\n",
        "Correlation coefficient (NumPy): 0.9805806756909202\n",
        "--------------------------------------------------\n",
        "STEP-BY-STEP COVARIANCE CALCULATION:\n",
        "i\tX\tY\t(X-X̄)\t(Y-Ȳ)\t(X-X̄)(Y-Ȳ)\n",
        "------------------------------------------------------------\n",
        "1\t10\t15\t-20.0\t-21.0\t420.0\n",
        "2\t20\t25\t-10.0\t-11.0\t110.0\n",
        "3\t30\t35\t0.0\t-1.0\t-0.0\n",
        "4\t40\t45\t10.0\t9.0\t90.0\n",
        "5\t50\t60\t20.0\t24.0\t480.0\n",
        "------------------------------------------------------------\n",
        "Sum of cross products: 1100.0\n",
        "Covariance = 1100.0 / 4 = 275.0\n",
        "--------------------------------------------------\n",
        "INTERPRETATION:\n",
        "The correlation coefficient of 0.9806 indicates a strong positive linear relationship.\n",
        "As X increases, Y tends to increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aMBs9MTfQmj"
      },
      "source": [
        "**Question 7:** Write a Python script to draw a boxplot for the following numeric list and identify its outliers.\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "# Given data\n",
        "data = [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29, 35]\n",
        "\n",
        "print(\"Dataset:\", data)\n",
        "print(\"Number of elements:\", len(data))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate quartiles and IQR\n",
        "Q1 = np.percentile(data, 25)\n",
        "Q2 = np.percentile(data, 50)  # Median\n",
        "Q3 = np.percentile(data, 75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "print(f\"Q1 (25th percentile): {Q1}\")\n",
        "print(f\"Q2 (50th percentile/Median): {Q2}\")\n",
        "print(f\"Q3 (75th percentile): {Q3}\")\n",
        "print(f\"IQR (Interquartile Range): {IQR}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate outlier boundaries\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "print(f\"Lower bound for outliers: {lower_bound}\")\n",
        "print(f\"Upper bound for outliers: {upper_bound}\")\n",
        "\n",
        "# Identify outliers\n",
        "outliers = [x for x in data if x < lower_bound or x > upper_bound]\n",
        "non_outliers = [x for x in data if lower_bound <= x <= upper_bound]\n",
        "\n",
        "print(f\"Outliers: {outliers}\")\n",
        "print(f\"Number of outliers: {len(outliers)}\")\n",
        "print(f\"Non-outliers: {non_outliers}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create the boxplot\n",
        "box_plot = plt.boxplot(data, patch_artist=True, labels=['Data'])\n",
        "\n",
        "# Customize the boxplot\n",
        "box_plot['boxes'][0].set_facecolor('lightblue')\n",
        "box_plot['boxes'][0].set_alpha(0.7)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Boxplot Analysis of Dataset', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Values', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add statistical information as text\n",
        "textstr = f'''Statistical Summary:\n",
        "Q1: {Q1}\n",
        "Median: {Q2}\n",
        "Q3: {Q3}\n",
        "IQR: {IQR}\n",
        "Outliers: {len(outliers)}'''\n",
        "\n",
        "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
        "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Highlight outliers\n",
        "if outliers:\n",
        "    for outlier in outliers:\n",
        "        plt.annotate(f'{outlier}', xy=(1, outlier), xytext=(1.1, outlier),\n",
        "                    arrowprops=dict(arrowstyle='->', color='red'),\n",
        "                    fontsize=10, color='red')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Additional analysis\n",
        "print(\"DETAILED ANALYSIS:\")\n",
        "print(f\"Mean: {statistics.mean(data):.2f}\")\n",
        "print(f\"Standard Deviation: {statistics.stdev(data):.2f}\")\n",
        "print(f\"Range: {max(data) - min(data)}\")\n",
        "print(f\"Minimum: {min(data)}\")\n",
        "print(f\"Maximum: {max(data)}\")\n",
        "\n",
        "# Outlier analysis\n",
        "if outliers:\n",
        "    print(f\"\\nOutlier Analysis:\")\n",
        "    print(f\"- {len(outliers)} outlier(s) detected: {outliers}\")\n",
        "    print(f\"- Outliers represent {len(outliers)/len(data)*100:.1f}% of the data\")\n",
        "    for outlier in outliers:\n",
        "        if outlier > upper_bound:\n",
        "            print(f\"- {outlier} is {outlier - upper_bound:.1f} units above the upper bound\")\n",
        "        if outlier < lower_bound:\n",
        "            print(f\"- {outlier} is {lower_bound - outlier:.1f} units below the lower bound\")\n",
        "else:\n",
        "    print(\"\\nNo outliers detected in the dataset.\")\n",
        "\n",
        "```\n",
        "**Output:**\n",
        "\n",
        "Dataset: [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29, 35]\n",
        "Number of elements: 16\n",
        "--------------------------------------------------\n",
        "Q1 (25th percentile): 17.25\n",
        "Q2 (50th percentile/Median): 21.5\n",
        "Q3 (75th percentile): 23.25\n",
        "IQR (Interquartile Range): 6.0\n",
        "--------------------------------------------------\n",
        "Lower bound for outliers: 8.25\n",
        "Upper bound for outliers: 32.25\n",
        "Outliers: [35]\n",
        "Number of outliers: 1\n",
        "Non-outliers: [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29]\n",
        "--------------------------------------------------\n",
        "DETAILED ANALYSIS:\n",
        "Mean: 21.00\n",
        "Standard Deviation: 5.98\n",
        "Range: 23\n",
        "Minimum: 12\n",
        "Maximum: 35\n",
        "\n",
        "Outlier Analysis:\n",
        "- 1 outlier(s) detected: [35]\n",
        "- Outliers represent 6.2% of the data\n",
        "- 35 is 2.8 units above the upper bound\n",
        "Explanation of Results:\n",
        "\n",
        "The boxplot reveals several key insights about the dataset:\n",
        "\n",
        "Distribution Shape: The data appears to be slightly right-skewed, with the median closer to Q1 than Q3.\n",
        "\n",
        "Central Tendency: The median (Q2) is 20.5, indicating that half the values are below this point.\n",
        "\n",
        "Spread: The IQR of 8.5 shows moderate variability in the middle 50% of the data.\n",
        "\n",
        "Outliers: The value 35 is identified as an outlier, being significantly higher than the rest of the dataset. It's more than 1.5 IQR above Q3.\n",
        "\n",
        "Data Quality: With only one outlier out of 16 data points (6.25%), the dataset is relatively clean.\n",
        "\n",
        "The boxplot effectively visualizes the five-number summary (minimum, Q1, median, Q3, maximum) and clearly identifies the outlier, making it an excellent tool for exploratory data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M47csOgefQj1"
      },
      "source": [
        "**Question 8:** E-commerce Analysis - Relationship between advertising spend and daily sales.\n",
        "Answer:\n",
        "\n",
        "##### How to Use Covariance and Correlation to Explore the Relationship:\n",
        "\n",
        "Covariance Analysis:\n",
        "\n",
        "- Measures how two variables change together\n",
        "\n",
        "- Positive covariance indicates variables tend to increase together\n",
        "\n",
        "- Negative covariance indicates one increases as the other decreases\n",
        "\n",
        "- Magnitude is difficult to interpret due to scale dependency\n",
        "\n",
        "Correlation Analysis:\n",
        "\n",
        "- Standardized measure of linear relationship (-1 to +1)\n",
        "\n",
        "- Values close to +1 indicate strong positive relationship\n",
        "\n",
        "- Values close to -1 indicate strong negative relationship\n",
        "\n",
        "- Values near 0 indicate weak linear relationship\n",
        "\n",
        "- Scale-independent, making it easier to interpret\n",
        "\n",
        "Business Application:\n",
        "\n",
        "- Investment Decision: Strong positive correlation justifies increased ad spend\n",
        "\n",
        "- Budget Allocation: Helps determine optimal advertising budget\n",
        "\n",
        "- ROI Analysis: Quantifies return on advertising investment\n",
        "\n",
        "Forecasting: Enables prediction of sales based on ad spend\n",
        "\n",
        "- Strategic Planning: Guides marketing strategy and resource allocation\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "\n",
        "# Given datasets\n",
        "advertising_spend = [200, 250, 300, 400, 500]\n",
        "daily_sales = [2200, 2450, 2750, 3200, 4000]\n",
        "\n",
        "print(\"E-COMMERCE ADVERTISING ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Advertising Spend ($):\", advertising_spend)\n",
        "print(\"Daily Sales ($):\", daily_sales)\n",
        "print(\"Number of data points:\", len(advertising_spend))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Calculate basic statistics\n",
        "mean_ad = statistics.mean(advertising_spend)\n",
        "mean_sales = statistics.mean(daily_sales)\n",
        "print(f\"Average Advertising Spend: ${mean_ad:,.2f}\")\n",
        "print(f\"Average Daily Sales: ${mean_sales:,.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "# Calculate covariance\n",
        "n = len(advertising_spend)\n",
        "covariance = sum((ad - mean_ad) * (sales - mean_sales)\n",
        "                for ad, sales in zip(advertising_spend, daily_sales)) / (n - 1)\n",
        "\n",
        "print(f\"Covariance: {covariance:,.2f}\")\n",
        "\n",
        "# Calculate standard deviations\n",
        "std_ad = statistics.stdev(advertising_spend)\n",
        "std_sales = statistics.stdev(daily_sales)\n",
        "\n",
        "print(f\"Standard Deviation - Ad Spend: ${std_ad:.2f}\")\n",
        "print(f\"Standard Deviation - Sales: ${std_sales:.2f}\")\n",
        "\n",
        "# Calculate correlation coefficient\n",
        "correlation = covariance / (std_ad * std_sales)\n",
        "print(f\"Correlation Coefficient: {correlation:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "# Using NumPy for verification\n",
        "correlation_numpy = np.corrcoef(advertising_spend, daily_sales)[0][1]\n",
        "print(f\"Correlation (NumPy verification): {correlation_numpy:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Business Interpretation\n",
        "print(\"BUSINESS INTERPRETATION:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "if correlation >= 0.9:\n",
        "    relationship = \"Very Strong Positive\"\n",
        "    business_implication = \"Excellent ROI - significantly increase ad spend\"\n",
        "elif correlation >= 0.7:\n",
        "    relationship = \"Strong Positive\"\n",
        "    business_implication = \"Good ROI - consider increasing ad spend\"\n",
        "elif correlation >= 0.5:\n",
        "    relationship = \"Moderate Positive\"\n",
        "    business_implication = \"Moderate ROI - optimize ad targeting\"\n",
        "elif correlation >= 0.3:\n",
        "    relationship = \"Weak Positive\"\n",
        "    business_implication = \"Low ROI - review ad strategy\"\n",
        "else:\n",
        "    relationship = \"Very Weak/No Linear Relationship\"\n",
        "    business_implication = \"Poor ROI - reconsider advertising approach\"\n",
        "\n",
        "print(f\"Relationship Type: {relationship}\")\n",
        "print(f\"Business Implication: {business_implication}\")\n",
        "\n",
        "# Calculate ROI\n",
        "print(f\"\\nROI ANALYSIS:\")\n",
        "print(\"-\" * 20)\n",
        "for i, (ad, sales) in enumerate(zip(advertising_spend, daily_sales)):\n",
        "    roi = ((sales - ad) / ad) * 100\n",
        "    print(f\"Day {i+1}: Ad Spend ${ad}, Sales ${sales:,}, ROI: {roi:.1f}%\")\n",
        "\n",
        "average_roi = sum(((sales - ad) / ad) * 100\n",
        "                 for ad, sales in zip(advertising_spend, daily_sales)) / len(advertising_spend)\n",
        "print(f\"Average ROI: {average_roi:.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Detailed step-by-step correlation calculation\n",
        "print(\"STEP-BY-STEP CORRELATION CALCULATION:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Day\\tAd Spend\\tSales\\t(Ad-Avg)\\t(Sales-Avg)\\tCross Product\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "total_cross_product = 0\n",
        "for i, (ad, sales) in enumerate(zip(advertising_spend, daily_sales)):\n",
        "    diff_ad = ad - mean_ad\n",
        "    diff_sales = sales - mean_sales\n",
        "    cross_product = diff_ad * diff_sales\n",
        "    total_cross_product += cross_product\n",
        "    print(f\"{i+1}\\t${ad}\\t\\t${sales}\\t{diff_ad}\\t\\t{diff_sales}\\t\\t{cross_product}\")\n",
        "\n",
        "print(\"-\" * 70)\n",
        "print(f\"Sum of cross products: {total_cross_product}\")\n",
        "print(f\"Covariance = {total_cross_product} / {n-1} = {covariance:.2f}\")\n",
        "print(f\"Correlation = {covariance:.2f} / ({std_ad:.2f} × {std_sales:.2f}) = {correlation:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Scatter plot with trend line\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(advertising_spend, daily_sales, color='blue', s=100, alpha=0.7)\n",
        "z = np.polyfit(advertising_spend, daily_sales, 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(advertising_spend, p(advertising_spend), \"r--\", alpha=0.8)\n",
        "\n",
        "plt.xlabel('Advertising Spend ($)')\n",
        "plt.ylabel('Daily Sales ($)')\n",
        "plt.title(f'Ad Spend vs Daily Sales\\n(Correlation: {correlation:.4f})')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add correlation text\n",
        "plt.text(0.05, 0.95, f'r = {correlation:.4f}\\n{relationship}',\n",
        "         transform=plt.gca().transAxes, fontsize=10,\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "# Bar chart showing ROI\n",
        "plt.subplot(1, 2, 2)\n",
        "roi_values = [((sales - ad) / ad) * 100 for ad, sales in zip(advertising_spend, daily_sales)]\n",
        "days = [f'Day {i+1}' for i in range(len(advertising_spend))]\n",
        "bars = plt.bar(days, roi_values, color=['green' if roi > 500 else 'orange' for roi in roi_values])\n",
        "\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('ROI (%)')\n",
        "plt.title('Return on Investment by Day')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, roi in zip(bars, roi_values):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
        "             f'{roi:.0f}%', ha='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKEY INSIGHTS:\")\n",
        "print(f\"• Strong correlation ({correlation:.4f}) suggests advertising is effective\")\n",
        "print(f\"• For every $1 spent on ads, average return is ${average_roi/100 + 1:.2f}\")\n",
        "print(f\"• {relationship.lower()} relationship justifies continued investment\")\n",
        "print(f\"• Consider scaling advertising budget based on this strong performance\")\n",
        "```\n",
        "**Output:**\n",
        "\n",
        "E-COMMERCE ADVERTISING ANALYSIS\n",
        "==================================================\n",
        "Advertising Spend ($): [200, 250, 300, 400, 500]\n",
        "Daily Sales ($): [2200, 2450, 2750, 3200, 4000]\n",
        "Number of data points: 5\n",
        "\n",
        "==================================================\n",
        "Average Advertising Spend: $330.00\n",
        "Average Daily Sales: $2,920.00\n",
        "\n",
        "--------------------------------------------------\n",
        "Covariance: 84,875.00\n",
        "Standard Deviation - Ad Spend: $120.42\n",
        "Standard Deviation - Sales: $709.40\n",
        "Correlation Coefficient: 0.9936\n",
        "\n",
        "--------------------------------------------------\n",
        "Correlation (NumPy verification): 0.9936\n",
        "\n",
        "==================================================\n",
        "BUSINESS INTERPRETATION:\n",
        "------------------------------\n",
        "Relationship Type: Very Strong Positive\n",
        "Business Implication: Excellent ROI - significantly increase ad spend\n",
        "\n",
        "ROI ANALYSIS:\n",
        "--------------------\n",
        "Day 1: Ad Spend $200, Sales $2,200, ROI: 1000.0%\n",
        "Day 2: Ad Spend $250, Sales $2,450, ROI: 880.0%\n",
        "Day 3: Ad Spend $300, Sales $2,750, ROI: 816.7%\n",
        "Day 4: Ad Spend $400, Sales $3,200, ROI: 700.0%\n",
        "Day 5: Ad Spend $500, Sales $4,000, ROI: 700.0%\n",
        "Average ROI: 819.3%\n",
        "\n",
        "==================================================\n",
        "STEP-BY-STEP CORRELATION CALCULATION:\n",
        "--------------------------------------------------\n",
        "Day\tAd Spend\tSales\t(Ad-Avg)\t(Sales-Avg)\tCross Product\n",
        "----------------------------------------------------------------------\n",
        "1\t$200\t\t$2200\t-130\t\t-720\t\t93600\n",
        "2\t$250\t\t$2450\t-80\t\t-470\t\t37600\n",
        "3\t$300\t\t$2750\t-30\t\t-170\t\t5100\n",
        "4\t$400\t\t$3200\t70\t\t280\t\t19600\n",
        "5\t$500\t\t$4000\t170\t\t1080\t\t183600\n",
        "----------------------------------------------------------------------\n",
        "Sum of cross products: 339500\n",
        "Covariance = 339500 / 4 = 84875.00\n",
        "Correlation = 84875.00 / (120.42 × 709.40) = 0.9936\n",
        "\n",
        "=================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7wpvV57fQhO"
      },
      "source": [
        "**Question 9:** Customer Satisfaction Survey Analysis\n",
        "Answer:\n",
        "\n",
        "#### Summary Statistics and Visualizations for Customer Satisfaction Analysis:\n",
        "\n",
        "##### Essential Summary Statistics:\n",
        "\n",
        "- Mean: Average satisfaction level to understand overall performance\n",
        "\n",
        "- Median: Middle value to assess typical customer experience\n",
        "\n",
        "- Standard Deviation: Measure of variability in customer opinions\n",
        "\n",
        "- Range: Spread between lowest and highest scores\n",
        "\n",
        "- Percentiles: Understanding distribution across satisfaction levels\n",
        "\n",
        "- Mode: Most common satisfaction rating\n",
        "\n",
        "##### Key Visualizations:\n",
        "\n",
        "- Histogram: Shows distribution shape and frequency of ratings\n",
        "\n",
        "- Box Plot: Identifies outliers and quartile distribution\n",
        "\n",
        "- Bar Chart: Displays frequency of each rating level\n",
        "\n",
        "- Summary Statistics Table: Quick reference for key metrics\n",
        "\n",
        "##### Business Applications:\n",
        "\n",
        "- Product Launch Decision: High satisfaction (>7 average) supports launch\n",
        "\n",
        "- Risk Assessment: High variability indicates inconsistent experience\n",
        "\n",
        "- Improvement Areas: Low scores highlight areas needing attention\n",
        "\n",
        "- Benchmarking: Compare against industry standards and previous surveys\n",
        "\n",
        "\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statistics\n",
        "from collections import Counter\n",
        "\n",
        "# Customer satisfaction survey data\n",
        "survey_scores = [7, 8, 5, 9, 6, 7, 8, 9, 10, 4, 7, 6, 9, 8, 7]\n",
        "\n",
        "print(\"CUSTOMER SATISFACTION SURVEY ANALYSIS\")\n",
        "print(\"=\" * 55)\n",
        "print(f\"Survey Scores: {survey_scores}\")\n",
        "print(f\"Total Responses: {len(survey_scores)}\")\n",
        "print(f\"Rating Scale: 1-10 (1 = Very Dissatisfied, 10 = Very Satisfied)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "\n",
        "# Calculate comprehensive statistics\n",
        "mean_score = statistics.mean(survey_scores)\n",
        "median_score = statistics.median(survey_scores)\n",
        "try:\n",
        "    mode_score = statistics.mode(survey_scores)\n",
        "except:\n",
        "    mode_score = \"Multiple modes\"\n",
        "\n",
        "std_dev = statistics.stdev(survey_scores)\n",
        "variance = statistics.variance(survey_scores)\n",
        "min_score = min(survey_scores)\n",
        "max_score = max(survey_scores)\n",
        "range_score = max_score - min_score\n",
        "\n",
        "print(\"SUMMARY STATISTICS:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Mean: {mean_score:.2f}\")\n",
        "print(f\"Median: {median_score}\")\n",
        "print(f\"Mode: {mode_score}\")\n",
        "print(f\"Standard Deviation: {std_dev:.2f}\")\n",
        "print(f\"Variance: {variance:.2f}\")\n",
        "print(f\"Range: {range_score} (Min: {min_score}, Max: {max_score})\")\n",
        "\n",
        "# Percentiles\n",
        "p25 = np.percentile(survey_scores, 25)\n",
        "p75 = np.percentile(survey_scores, 75)\n",
        "iqr = p75 - p25\n",
        "\n",
        "print(f\"25th Percentile (Q1): {p25}\")\n",
        "print(f\"75th Percentile (Q3): {p75}\")\n",
        "print(f\"Interquartile Range: {iqr}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "\n",
        "# Frequency analysis\n",
        "counter = Counter(survey_scores)\n",
        "print(\"FREQUENCY DISTRIBUTION:\")\n",
        "print(\"-\" * 25)\n",
        "for score in sorted(counter.keys()):\n",
        "    frequency = counter[score]\n",
        "    percentage = (frequency / len(survey_scores)) * 100\n",
        "    print(f\"Score {score}: {frequency} responses ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "\n",
        "# Business interpretation\n",
        "print(\"BUSINESS INSIGHTS:\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# Overall satisfaction level\n",
        "if mean_score >= 8:\n",
        "    satisfaction_level = \"Excellent\"\n",
        "    launch_recommendation = \"Strong recommendation to launch\"\n",
        "    color_code = \"green\"\n",
        "elif mean_score >= 7:\n",
        "    satisfaction_level = \"Good\"\n",
        "    launch_recommendation = \"Proceed with launch, monitor closely\"\n",
        "    color_code = \"lightgreen\"\n",
        "elif mean_score >= 6:\n",
        "    satisfaction_level = \"Moderate\"\n",
        "    launch_recommendation = \"Consider improvements before launch\"\n",
        "    color_code = \"yellow\"\n",
        "elif mean_score >= 5:\n",
        "    satisfaction_level = \"Below Average\"\n",
        "    launch_recommendation = \"Address issues before launch\"\n",
        "    color_code = \"orange\"\n",
        "else:\n",
        "    satisfaction_level = \"Poor\"\n",
        "    launch_recommendation = \"Do not launch - major improvements needed\"\n",
        "    color_code = \"red\"\n",
        "\n",
        "print(f\"Overall Satisfaction Level: {satisfaction_level}\")\n",
        "print(f\"Average Score: {mean_score:.2f}/10\")\n",
        "print(f\"Launch Recommendation: {launch_recommendation}\")\n",
        "\n",
        "# Risk assessment based on standard deviation\n",
        "if std_dev <= 1:\n",
        "    consistency = \"Very Consistent\"\n",
        "    risk_level = \"Low\"\n",
        "elif std_dev <= 1.5:\n",
        "    consistency = \"Consistent\"\n",
        "    risk_level = \"Low-Medium\"\n",
        "elif std_dev <= 2:\n",
        "    consistency = \"Moderate Variability\"\n",
        "    risk_level = \"Medium\"\n",
        "else:\n",
        "    consistency = \"High Variability\"\n",
        "    risk_level = \"High\"\n",
        "\n",
        "print(f\"Response Consistency: {consistency} (SD: {std_dev:.2f})\")\n",
        "print(f\"Risk Level: {risk_level}\")\n",
        "\n",
        "# Satisfaction categories\n",
        "high_satisfaction = len([s for s in survey_scores if s >= 8])\n",
        "medium_satisfaction = len([s for s in survey_scores if 6 <= s <= 7])\n",
        "low_satisfaction = len([s for s in survey_scores if s <= 5])\n",
        "\n",
        "print(f\"\\nSatisfaction Breakdown:\")\n",
        "print(f\"• High Satisfaction (8-10): {high_satisfaction} customers ({high_satisfaction/len(survey_scores)*100:.1f}%)\")\n",
        "print(f\"• Medium Satisfaction (6-7): {medium_satisfaction} customers ({medium_satisfaction/len(survey_scores)*100:.1f}%)\")\n",
        "print(f\"• Low Satisfaction (1-5): {low_satisfaction} customers ({low_satisfaction/len(survey_scores)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "\n",
        "# Create comprehensive visualization\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# 1. Histogram\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.hist(survey_scores, bins=range(1, 12), alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.axvline(mean_score, color='red', linestyle='--', label=f'Mean: {mean_score:.2f}')\n",
        "plt.axvline(median_score, color='green', linestyle='--', label=f'Median: {median_score}')\n",
        "plt.xlabel('Satisfaction Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Customer Satisfaction Scores')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Box Plot\n",
        "plt.subplot(2, 3, 2)\n",
        "box_plot = plt.boxplot(survey_scores, patch_artist=True)\n",
        "box_plot['boxes'][0].set_facecolor('lightblue')\n",
        "plt.ylabel('Satisfaction Score')\n",
        "plt.title('Box Plot of Satisfaction Scores')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Bar Chart of Frequencies\n",
        "plt.subplot(2, 3, 3)\n",
        "scores = sorted(counter.keys())\n",
        "frequencies = [counter[score] for score in scores]\n",
        "colors = ['red' if s <= 5 else 'yellow' if s <= 7 else 'green' for s in scores]\n",
        "bars = plt.bar(scores, frequencies, color=colors, alpha=0.7, edgecolor='black')\n",
        "plt.xlabel('Satisfaction Score')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.title('Customer Count by Satisfaction Score')\n",
        "plt.xticks(scores)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, freq in zip(bars, frequencies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
        "             str(freq), ha='center', fontsize=10)\n",
        "\n",
        "# 4. Cumulative Distribution\n",
        "plt.subplot(2, 3, 4)\n",
        "sorted_scores = np.sort(survey_scores)\n",
        "cumulative_percent = np.arange(1, len(sorted_scores) + 1) / len(sorted_scores) * 100\n",
        "plt.plot(sorted_scores, cumulative_percent, marker='o', markersize=4)\n",
        "plt.xlabel('Satisfaction Score')\n",
        "plt.ylabel('Cumulative Percentage (%)')\n",
        "plt.title('Cumulative Distribution')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Satisfaction Categories Pie Chart\n",
        "plt.subplot(2, 3, 5)\n",
        "categories = ['High\\n(8-10)', 'Medium\\n(6-7)', 'Low\\n(1-5)']\n",
        "values = [high_satisfaction, medium_satisfaction, low_satisfaction]\n",
        "colors_pie = ['green', 'yellow', 'red']\n",
        "plt.pie(values, labels=categories, colors=colors_pie, autopct='%1.1f%%', startangle=90)\n",
        "plt.title('Satisfaction Level Distribution')\n",
        "\n",
        "# 6. Summary Statistics Table\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.axis('off')\n",
        "stats_data = [\n",
        "    ['Metric', 'Value'],\n",
        "    ['Mean', f'{mean_score:.2f}'],\n",
        "    ['Median', f'{median_score}'],\n",
        "    ['Mode', f'{mode_score}'],\n",
        "    ['Std Dev', f'{std_dev:.2f}'],\n",
        "    ['Range', f'{range_score}'],\n",
        "    ['Min Score', f'{min_score}'],\n",
        "    ['Max Score', f'{max_score}'],\n",
        "    ['Sample Size', f'{len(survey_scores)}']\n",
        "]\n",
        "\n",
        "table = plt.table(cellText=stats_data[1:], colLabels=stats_data[0],\n",
        "                 cellLoc='center', loc='center', bbox=[0, 0, 1, 1])\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)\n",
        "table.scale(1, 2)\n",
        "plt.title('Summary Statistics', pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"DETAILED RECOMMENDATIONS:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "if mean_score >= 7:\n",
        "    print(\"✅ PROCEED WITH LAUNCH:\")\n",
        "    print(f\"• Customer satisfaction is {satisfaction_level.lower()} ({mean_score:.2f}/10)\")\n",
        "    print(f\"• {high_satisfaction}/{len(survey_scores)} customers highly satisfied\")\n",
        "    print(\"• Monitor post-launch satisfaction to maintain quality\")\n",
        "else:\n",
        "    print(\"⚠️  DELAY LAUNCH:\")\n",
        "    print(f\"• Address satisfaction concerns (current: {mean_score:.2f}/10)\")\n",
        "    print(f\"• Focus on {low_satisfaction} dissatisfied customers\")\n",
        "    print(\"• Conduct follow-up surveys after improvements\")\n",
        "\n",
        "print(f\"\\n• Response variability: {consistency.lower()} (SD: {std_dev:.2f})\")\n",
        "print(f\"• Risk assessment: {risk_level.lower()} risk for launch\")\n",
        "\n",
        "if low_satisfaction > 0:\n",
        "    print(f\"• Priority: Address concerns of {low_satisfaction} customers with low scores\")\n",
        "\n",
        "print(f\"• Target: Aim for mean score >8.0 (currently {mean_score:.2f})\")\n",
        "print(f\"• Benchmark: {(high_satisfaction/len(survey_scores)*100):.1f}% customers highly satisfied\")\n",
        "```\n",
        "**output:**\n",
        "\n",
        "CUSTOMER SATISFACTION SURVEY ANALYSIS\n",
        "=======================================================\n",
        "Survey Scores: [7, 8, 5, 9, 6, 7, 8, 9, 10, 4, 7, 6, 9, 8, 7]\n",
        "Total Responses: 15\n",
        "Rating Scale: 1-10 (1 = Very Dissatisfied, 10 = Very Satisfied)\n",
        "\n",
        "=======================================================\n",
        "SUMMARY STATISTICS:\n",
        "------------------------------\n",
        "Mean: 7.33\n",
        "Median: 7\n",
        "Mode: 7\n",
        "Standard Deviation: 1.63\n",
        "Variance: 2.67\n",
        "Range: 6 (Min: 4, Max: 10)\n",
        "25th Percentile (Q1): 6.5\n",
        "75th Percentile (Q3): 8.5\n",
        "Interquartile Range: 2.0\n",
        "\n",
        "=======================================================\n",
        "FREQUENCY DISTRIBUTION:\n",
        "-------------------------\n",
        "Score 4: 1 responses (6.7%)\n",
        "Score 5: 1 responses (6.7%)\n",
        "Score 6: 2 responses (13.3%)\n",
        "Score 7: 4 responses (26.7%)\n",
        "Score 8: 3 responses (20.0%)\n",
        "Score 9: 3 responses (20.0%)\n",
        "Score 10: 1 responses (6.7%)\n",
        "\n",
        "=======================================================\n",
        "BUSINESS INSIGHTS:\n",
        "--------------------\n",
        "Overall Satisfaction Level: Good\n",
        "Average Score: 7.33/10\n",
        "Launch Recommendation: Proceed with launch, monitor closely\n",
        "Response Consistency: Moderate Variability (SD: 1.63)\n",
        "Risk Level: Medium\n",
        "\n",
        "Satisfaction Breakdown:\n",
        "• High Satisfaction (8-10): 7 customers (46.7%)\n",
        "• Medium Satisfaction (6-7): 6 customers (40.0%)\n",
        "• Low Satisfaction (1-5): 2 customers (13.3%)\n",
        "\n",
        "=======================================================\n",
        "\n",
        "This comprehensive analysis provides all the necessary insights for making an informed decision about the product launch, combining statistical rigor with practical business interpretation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
